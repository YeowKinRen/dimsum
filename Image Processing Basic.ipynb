{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing : Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# https://likegeeks.com/python-image-processing/\n",
    "# https://www.geeksforgeeks.org/opencv-python-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Lenna.png\")\n",
    "# arg1 : full path of the image\n",
    "# arg2 [opt] : cv2.IMREAD_COLOR / 1 / cv2.IMREAD_UNCHANGED / -1 / cv2.IMREAD_GRAYSCALE / 0\n",
    "# colour image excluding alpha channel [default] / including alpha channel / grayscale mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width = img.shape[0:2]\n",
    "img.shape[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original Image', img) \n",
    "# arg1 : window name\n",
    "# arg2 : image\n",
    "cv2.waitKey(0) # keyboard binding function take time in milliseconds as a delay for the window to close\n",
    "cv2.destroyAllWindows() # destroy all created GUI window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('Lenna.png', img) # save image\n",
    "# arg1 : filename\n",
    "# arg2 : image to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Lenna.png') \n",
    "B, G, R = cv2.split(image) \n",
    "# Corresponding channels are seperated \n",
    "  \n",
    "cv2.imshow(\"original\", image) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "cv2.imshow(\"blue\", B) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "cv2.imshow(\"Green\", G) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "cv2.imshow(\"red\", R) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.addWeighted(image1, 0.5, image2, 0.4, 0)\n",
    "# cv2.add(img1, img2) # adds up image pixels in the two images.\n",
    "# cv2.subtract(src1, src2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise Operations on Binary Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.bitwise_and(source1, source2, destination, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.getRotationMatrix2D(center, angle, scale) \n",
    "# center is the center point of rotation, \n",
    "# the angle is the angle in degrees \n",
    "# scale is the scale property which makes the image fit on the screen.\n",
    "rotationMatrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "rotatedImage = cv2.warpAffine(img, rotationMatrix, (width, height))\n",
    "cv2.imshow('Rotated Image', rotatedImage) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop an Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRow = int(height*.15) \n",
    "startCol = int(width*.15) \n",
    "endRow = int(height*.85) \n",
    "endCol = int(width*.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedImage = img[startRow:endRow, startCol:endCol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Original Image', img) \n",
    "cv2.imshow('Cropped Image', croppedImage) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newImg = cv2.resize(img, (0,0), fx=0.75, fy=0.75) \n",
    "cv2.imshow('Resized Image', newImg) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newImg = cv2.resize(img, (550, 350)) \n",
    "cv2.imshow('Resized Image', newImg) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Image Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_img = a * original_img + b\n",
    "# a : contrast of the image. If a > 1 : higher contrast. If 0 <= a < 1 : lower contrast. If a = 1 : no contrast.\n",
    "# b vary from -127 to +127.\n",
    "# cv2.addWeighted(source_img1, alpha1, source_img2, alpha2, beta)\n",
    "# blend two images, the first source image (source_img1) with a weight of alpha1 and second source image (source_img2).\n",
    "import numpy as np\n",
    "\n",
    "contrast_img = cv2.addWeighted(img, 2.5, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Contrast Image', contrast_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an image blurry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur_image = cv2.GaussianBlur(img, (7,7), 0)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur_image = cv2.medianBlur(img,5)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Blur Image', blur_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.Canny(image, minVal, maxVal)\n",
    "# minimum and maximum intensity gradient values\n",
    "edge_img = cv2.Canny(img,100,200)\n",
    "cv2.imshow(\"Detected Edges\", edge_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to grayscale (Black & White)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.\n",
    "gray_img = cv2.imread(\"220px-Lenna_(test_image).png\", 0)\n",
    "cv2.imshow('Original Image', gray_img) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Gray Scale Image\", gray_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centroid (Center of blob) detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment = cv2.moments(gray_img)\n",
    "X = int(moment [\"m10\"] / moment[\"m00\"])\n",
    "Y = int(moment [\"m01\"] / moment[\"m00\"])\n",
    "cv2.circle(img, (X, Y), 15, (205, 114, 101), 1)\n",
    "cv2.imshow(\"Center of the Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a mask for a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('220px-Lenna_(test_image).png')\n",
    "img1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray_img = cv2.medianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 3)\n",
    "circles = cv2.HoughCircles(gray_img, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=50, minRadius=0, maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking=np.full((img1.shape[0], img1.shape[1]),0,dtype=np.uint8)\n",
    "\n",
    "for j in circles[0, :]:\n",
    "    cv2.circle(masking, (j[0], j[1]), j[2], (255, 255, 255), -1)\n",
    "    \n",
    "final_img = cv2.bitwise_or(img1, img1, mask=masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image\", final_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text from Image (OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image\", final_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
